---
title: "Golden Rules for Reproducible Statistical Analyses"
author: "Amy Gimma and Thibaut Jombart"
date: "`r format(Sys.time(), '%A %d %B %Y')`"
output:
  html_document:
    code_folding: show
    highlight: pygments
    number_sections: yes
    theme: spacelab
    toc: yes
    toc_collapse: no
    toc_depth: 2
    toc_float: yes
    css: !expr here::here('css', 'style.css')
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      collapse = TRUE,
                      fig.width = 8,
                      fig.height = 6,
                      dpi = 150,
                      warning = FALSE,
                      message = FALSE)
```


```{r read_scripts, echo = FALSE}

## read scripts
path_to_scripts <- here::here("scripts")

scripts_files <- dir(path_to_scripts, pattern = ".R$",
                     full.names = TRUE)
load_dictionary <- here::here("scripts", "load_dictionary.R")
for (file in scripts_files) if (!file == load_dictionary) source(file)

```


<!-- ===================================================== -->
<!-- ===================================================== -->
<!-- ===================================================== -->
<!-- Rule 1 -->
# Organize your document logically {.tabset .tabset-fade .tabset-pills}

<!-- ===================================================== -->
## Outline

A clear structure is essential for readers to understand and navigate your
analysis document. We recommend the following structure:

* Data preparation
* Analysis of *xxx*
* Analysis of *yyy*
* ...
* Export outputs
* (Optionally) System information

Where the analyses of *xxx*, *yyy*, ... should have identical structures, if
possible.



<!-- ===================================================== -->
## Data preparation

We recommend the following structure:

* **Load packages needed**

* **Load the raw data**

* **Clean the raw data** 
    + *standardise data* (e.g. `linelist::clean_data`)
    + *convert dates* that need converting (e.g. `linelist::guess_dates`)
    + *fix typos* (e.g. `linelist::clean_variable_spelling`)

* **Add new variables** (e.g. using `mutate`)

* **Subset entries** (rows) of the data (e.g. using `filter`)

* **Define custom colors** (e.g. using `scale_fill_manual` or `scale_color_manual`)



<!-- ===================================================== -->
## Data analysis

Organise the work in a systematic way, using one sub-section per type of
analysis, and starting with general analyses before subsetted or stratified
ones.

The following workflow should apply to most cases:

* **Data manipulations and computations**: this part will derive numbers and metrics
  needed by the analysis
  
* **Graphics**: graphical display of the results; we recommend using *ggplot2* where
  possible

* **Table**: a table providing numbers matching the graphics, and useful summary
  statistics, e.g. means, medians, confidence intervals, etc.



<!-- ===================================================== -->
## Export outputs

As a rule, we recommend to export every table displayed in the document to a
`.xlsx` and/or `.rds` files, so that they can be used in further analyses in R
(`.rds` file) or using other software. (`.xlsx` file). We recommend `.xlsx` over
text-based formats (e.g. `.txt`, `.csv`) as it preserves variable types.

The following code exports all tables named in `to_report` to `xslx` files,
stored inside the folder `produced_xlsx`; replace `xlsx` with `rds` for R files,
but in this case, do not insert the links as `rds` files cannot be opened within
a web browser (they are compressed binary representations of the data):

```{r xlsx_exports, eval = FALSE}

## create the produced_xlsx folder if it does not exist
if (!dir.exists("produced_xlsx")) {
  dir.create("produced_xlsx")
}

## vector of names of tables to export
## (these need to be existing data.frames or tibbles)
to_export <- c("table_1",
               "table_xxx",
               "table_yyy",
               "table_zzz")

## export all files
for (e in to_export) {
  rio::export(get(e),
              file.path("produced_xlsx",
                        paste0(e, ".xlsx")))
}

```

The following code will create links in your document pointing to the exported
files:

```{r links, results = "asis", eval = FALSE}

## note: for this to work, use the options `results = "asis"` and
## `echo = FALSE` in the code chunk header
for (e in to_export) {
  txt <- sprintf("- [%s.xlsx](%s.xlsx)",
                 e,
                 file.path("produced_xlsx",
                           e))
  cat(txt, sep = "\n")
}

```



<!-- ===================================================== -->
## System information

This is optional, but can be useful for audit purposes, or for diagnosing issues
in the results generated. We recommend including the following:

* `Sys.info()`: basic system information

* `R.version`: version of **R**

* `sessionInfo()`: which packages are loaded, and which versions are they?

* `params`: this list will contain optional parameters passed at compilation
  time through the `params` argument of `compile_report` or `update_reports`
  




<!-- ===================================================== -->
<!-- ===================================================== -->
<!-- ===================================================== -->
<!-- Rule 2 -->
# Follow standard naming conventions {.tabset .tabset-fade .tabset-pills}

<!-- ===================================================== -->
## Outline

Consistent and predictable naming helps streamline writing and reviewing
code. We recommend using the following conventions, already used to a large
extent in package development:

* **use only**: lower case letters, numbers, and `_` as separator (only use `-` for dates)

* **never use**: special characters in file names, variable names or values such as
  `éÈçôï\/# %?!&:;,@*^` and blank spaces

* if you really need to, only **use special characters only when defining labels**
  for graphics or tables
  
* **for dates**: use the format `yyyy-mm-dd`, e.g. `2001-10-13` for the 13th October
  2001.

* **for encoding**: use `UTF-8` encoding whenever possible, as it guarantees
  that special characters will display correctly on different computers

Note that all of these points, except for the encoding, will be achieved by
using `linelist::clean_data` on your `data.frame` or `tibble`.
 


## Example1: clean *vs* messy

The following data is messy for many reasons, as it violates all the above:

```{r messy}

messy <- linelist::messy_data(n = 10) %>% select(1:5)
messy

```

A clean version of this would be:

```{r clean_data}

clean <- clean_data(messy)
clean

```


## Example 2: special characters in graphics

Here we show how we can make exceptions to the naming conventions when
displaying graphics, without actually altering the data. We use the Korean MERS
dataset from the [*outbreaks*](https://www.repidemicsconsortium.org/outbreaks)
package, and use French labels to justify the accents:

```{r special_characters_graphics}

## load and clean data
mers <- outbreaks::mers_korea_2015$linelist %>%
  as_tibble() %>%
  clean_data()

mers

## define scales for sex and outcome, tweak labels as appropriate
scale_sex <- scale_fill_manual(
    "Sexe",
    values = c(m = "navy", f = "salmon"),
    labels = c(m = "Homme", f = "Femme"))

scale_x_outcome <- scale_x_discrete(
    labels = c(alive = "Vivant",
               dead = "Décédé"))

## make the plot
ggplot(mers, aes(x = outcome, fill = sex)) +
  geom_bar(position = "dodge") +
  scale_sex +
  scale_x_outcome +
  labs(title = "Issue de la maladie par sexe",
       x = "",
       y = "Nombre de cas")

```

Here, we are using accents, spaces, and upper-case letters for the graphics, but
because we restrict these to labels used in `scales`, the data remain clean,
respecting naming conventions.






<!-- ===================================================== -->
<!-- ===================================================== -->
<!-- ===================================================== -->
<!-- Rule 3 -->
# Use descriptive naming {.tabset .tabset-fade .tabset-pills}

<!-- ===================================================== -->
## Outline

All files and **R** objects should be named in an explicit way. There is a
trade-off between the length of a variable and explicit naming, but clarity is
often, if not always preferrable. Some exceptions can be made, e.g. by
systematically calling `x` your data.


<!-- ===================================================== -->
## Example

Here is an example of poor naming:

```{r naming_example_bad}

i <- iris %>%
  clean_data()
tab <- i %>%
  count(species)
tab

tab_2 <- i %>%
  group_by(species) %>%
  summarise_all(mean)
tab_2


a <- ggplot(i, aes(x = petal_width)) +
  geom_density(aes(fill = species), alpha = .4)
a

b <- ggplot(i, aes(x = petal_length)) +
  geom_density(aes(fill = species), alpha = .4)
b

```

This code is bad because:

* `iris`, the name of the dataset, is uselessly renamed to `i`, with no
  indication that the data has been cleaned

* `tab` and `tab_2` suggest these are *tables*, but provides no indication as to
  what they contain

* `a` and `b` are plots, but the name does not indicate that they are, or what
  the plots are about

A better version would be:

```{r naming_example_good}

iris_clean <- iris %>%
  clean_data()

table_species_counts <- iris_clean %>%
  count(species)
table_species_counts

table_species_means <- iris_clean %>%
  group_by(species) %>%
  summarise_all(mean)
table_species_means

plot_petal_width <- ggplot(iris_clean, aes(x = petal_width)) +
  geom_density(aes(fill = species), alpha = .4)
plot_petal_width

plot_petal_length <- ggplot(iris_clean, aes(x = petal_length)) +
  geom_density(aes(fill = species), alpha = .4)
plot_petal_length

```




<!-- ===================================================== -->
<!-- ===================================================== -->
<!-- ===================================================== -->
<!-- Rule 5 -->
# Show statistical variation / uncertainty {.tabset .tabset-fade .tabset-pills}

## Overview
Confidence intervals should be used: 

* to represet the uncertainty around generalisability from sample to population
* to represent uncertainty and variable conditions in data collection
* on predictions and imputations



```

 -------------------------    |Yes|----- **Include Confidence Interval**
|                         |     |  
|     Might the value     |     |
| observed be different   |-----|
| with a larger sample?   |     |                 |Yes|--| **CI not required**
|                         |     |    -----------   |
 -------------------------    |No|--| You sure? |--|
                                     -----------   |
                                                  |No|-- **Ask a statistician!**
```

## Example

Let us make some toy data, and plot a trend **without showing dispersion** in
the data:

```{r rule_5, fig.width = 4, fig.height = 4, fig.pos = "center"}

set.seed(1)
x <- rep(1:50, each = 15)
y <- rnorm(length(x), mean = 1)
df <- data.frame(x, y)

ggplot(df, aes(x = x, y = y)) +
  theme_bw() +
  geom_smooth() +
  labs(title = "Is there a trend here?")

```

Looking at this graph, **we may think there is a downward trend**, and start
interpreting what it means etc. **In fact, this is purely artifactual**. Data
have been generated in such a way that there is no correlation between the two
variables. This would be obvious if we add the data, thereby representing the
variability in the data:

```{r rule_5_2, fig.width = 4, fig.height = 4, fig.pos = "center"}

ggplot(df, aes(x = x, y = y)) +
  theme_bw() +
  geom_point() +
  geom_smooth() +
  labs(title = "No, there is not!")

```





<!-- Rule 6 -->
# Code systematically {.tabset .tabset-fade .tabset-pills}

## Overview

Be consistent in functions in libraries used

* *use `linelist::clean_data`* with a data dictionary for cleaning dates,
column names and values, etc. Take the time to understand how to use this 
package and how it works.

* for example choose between `n()`, `tally()`, and `count()` when summarizing
grouped data



## Example

Let's look at some basic code to count cases by location, gender and outcomes on
the MERS dataset from the `outbreaks` package.

```{r rule_6}

mers <- outbreaks::mers_korea_2015$linelist %>%
  as_tibble()

# 2x2 table 1: location / sex
mers %>%
  group_by(place_infect, sex) %>%
  summarise(n = n())

## 2x2 table 2: location / outcome
loc_out_tab <- count(mers, place_infect, outcome)
loc_out_tab

##################################
## 2x2 table 3: location / outcome
##################################
table_sex_outcome <- with(mers, table(sex, outcome)) %>% as.data.frame() %>% as_tibble
table_sex_outcome

```

The code is correct, but there are plenty of consistency issues here; to name a
few:

* using 3 different approaches to construct the 2x2 tables

* not using the piping operator ` %>% ` in table 2, but using it elsewhere

* annotations are not consistent

* not going back to a new line after the piping operators for table 3

* in table 3, not using parenthesis for `as_tibble`, but using them for
  `as.data.frame()`

* storing the 2nd and 3rd table as objects, but not for the 1st one

* using different naming conventions: table 2 is abbreviated and `tab` comes
  last, whilst table 3 is explicit and `table` comes first in the name
  
A more consistent version of the code would look like:

```{r rule_6_2}

## 2x2 table 1: location / sex
table_location_sex <- mers %>%
  count(place_infect, sex)
table_location_sex

## 2x2 table 2: location / outcome
table_location_outcome <- mers %>%
  count(place_infect, outcome)
table_location_outcome

## 2x2 table 3: location / outcome
table_sex_outcome <- mers %>%
  count(sex, outcome)
table_sex_outcome

```



<!-- Rule 7 -->
# Always use relative paths {.tabset .tabset-fade .tabset-pills}

Absolute paths will not work when the code is run on other computers. Use the
`here` library with R project files to establish a root directory

```{r eval = FALSE}

## NOT:
read.csv("P://user/specific/path/to/shared/directory/data/file_name.csv")

## Use:
read.csv(here::here("data", "file_name.csv")


```



<!-- Rule 8 -->
# Version and archive documents {.tabset .tabset-fade .tabset-pills}

Use semantic versioning in a clearly organized, standardized file structure

```
.
+-- linelist_investigations
|   +-- css
|   +-- data
|   +-- report_outputs
|   +-- report_sources
|       +-- aaa_clean_linelist_2019-29-09.Rmd
|       +-- epicurve_2019-04-10.Rmd
|       +-- _archive
|           +-- epicurve_2019-23-09.Rmd
|           +-- epicurve_2019-12-09.Rmd

```


<!-- Rule 10 -->
# Prepare presentation-ready plots {.tabset .tabset-fade .tabset-pills}

**Plots should be ready to copy and paste into an official presentation**

* check labels for correct spelling, accents, and grammar 
* uniform colors for variables throughout a document
* text size large
* avoid overlapping labels or other features


<!-- Rule 11 -->
# Always have your code reviewed {.tabset .tabset-fade .tabset-pills}

Ensure that:

* Analysis is appropriate to setting and underlying data is well understood, 
local collaborators should be included and acknowledged
* statistical methodology is applied correctly
* R code is readable and correctly implements methodology 
* markdown and the report document are well organized and properly formatted

<!-- Rule 12 -->
# Keep data safe {.tabset .tabset-fade .tabset-pills}

* Respect the privacy of the individuals described in the data

* Never label data as anonomysed without complying with best practices of the
standards and methods of anonymyzation (and clear final product with a 
qualified statistician)
